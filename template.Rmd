---
title: "STAT 345 Address Final Project"
output: word_document
date: "2025-11-12"
authors: "Isaac Dhyanchand, Blake Guilette, James Jegier"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The purpose of this project is to explore how address-related geographic features vary across the United States at the county level. Using publicly available spatial data from the U.S. Census Bureau, we first constructed a complete county boundary map of the United States. We then summarized road suffixes by county. Finally, we merged these summaries back into the county map and produced visualizations that highlight geographic patterns in road naming and related county-level characteristics. Throughout the project, we focused on making readable code, building time-efficient functions, and building collaborative coding skills.

## Data Sources

All primary spatial data used in this project comes from publicly available government sources. County boundary shapefiles were obtained from the U.S. Census Bureau’s TIGER/Line products, accessed both through direct downloads and the tigris R package (https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). Road-level data were sourced from the TIGER/Line ROADS directory (https://www2.census.gov/geo/tiger/TIGER2023/ROADS/), which provides individual shapefiles for each U.S. county identified by a five-digit GEOID. For additional visualizations, county-level hazard risk data were obtained from FEMA’s National Risk Index shapefiles (https://hazards.fema.gov/nri/data-resources#shpDownload). These datasets were chosen because they are well-documented and widely used,

## Step 1: Mapping U.S. County Boundaries

The first step in the analysis was to create a base map that displays county boundaries for the entire United States. We used detailed TIGER/Line county shapefiles and processed them using the sf package. To ensure an appropriate size for our map, the data was transformed, removing non-continental territories to maintain a consistent geographic scope. This county map serves as the spatial foundation for all of our analysis and visualization. The code for this is below.

```{r}
library(tigris)
library(sf)
library(ggplot2)
library(tidyverse)

# - tigris: Downloads US Census TIGER/Line geographic data (counties, roads, etc.)
# - sf: "Simple Features" package for working with spatial data (points, lines, polygons)

options(tigris_use_cache = TRUE)
# - Tells tigris to CACHE (save locally) downloaded data


# Download U.s.County Boundries
us_counties <- counties(cb = FALSE, class = "sf")

# - counties() is a tigris function that downloads US county shapefile
# - cb = FALSE: downloads DETAILED TIGER geometry (full county boundaries)

# Remove any invalid or empty geometries
us_counties <- st_make_valid(us_counties)
us_counties <- us_counties[!st_is_empty(us_counties), ]

# keep only contiguous US
state_keep <- tigris::states(cb = TRUE) |> 
  st_drop_geometry() |>
  filter(!STUSPS %in% c("AS","GU","MP","PR","VI", "AK", "HI")) |>  # drop territories and states not contiguous
  pull(STATEFP)

us_counties <- us_counties |> 
  filter(STATEFP %in% state_keep)

# - st_make_valid(): Fixes any self-intersecting or invalid polygons 
# - [!st_is_empty(us_counties), ]: Removes rows where geometry is empty

# Print prgress and data
cat("✓ Downloaded ", nrow(us_counties), " county records\n", sep = "")


cat("  Geometry type: ", unique(st_geometry_type(us_counties)), "\n", sep = "")


# - st_geometry_type() tells you what kind of shape each row is (POLYGON, MULTIPOLYGON, etc.)
# - unique() shows only the distinct types (all should be POLYGON or MULTIPOLYGON)

# was used to shift the states that weren't contiguous but we aren't doing that anymore
us_counties_shift <- us_counties


# create directories for outputs
if (!dir.exists("data_raw")) dir.create("data_raw", recursive = TRUE)
if (!dir.exists("data_processed")) dir.create("data_processed", recursive = TRUE)
if (!dir.exists("figures")) dir.create("figures", recursive = TRUE)

# Creates three folders


# Save Raw data
saveRDS(us_counties, "data_raw/counties_us_tiger.rds")

# - Next time this script is ran, tigris will use cached version 
# File format: .rds is R's native binary format
# - Smaller than CSV (compressed)
# - Preserves all R object structure (columns, types, spatial info)


# Create Map 
map_counties <- ggplot(us_counties_shift) +
  geom_sf(fill = NA, color = "gray30", linewidth = 0.1) +
  coord_sf(crs = 5070) +   #crs = 5070 is the standard mapping system and makes it so US is portrayed as ture size
  theme_void() + # removes ticks, gridmarks, nonesetial parts
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray40")
  ) +
  labs(
    title = "United States County Boundaries",
    subtitle = "TIGER/Line 2023 | n = 3,233 counties | EPSG:5070"
  )


# Save Map as png
ggsave(
  "figures/01_us_counties_base_map.png",
  plot = map_counties,
  width = 16,
  height = 10,
  dpi = 300,
  units = "in"
)

print(map_counties)


us_counties_shift_proj <- st_transform(us_counties_shift, crs = 5070)


# - st_transform(): Converts/reprojects spatial data to a new CRS
# - crs = 5070: Project to EPSG:5070 (same as what the map uses)
# - Stores result in new object: us_counties_shift_proj

saveRDS(us_counties_shift_proj, "data_processed/counties_us_shift_5070.rds")

# What it does:
# - Saves the projected counties as .rds file to data_processed
# so that in the next part this code does not have to be reran


# Summary
cat("Summary:\n")
cat("  • Total counties: ", nrow(us_counties), "\n", sep = "")
cat("  • States: ", n_distinct(us_counties$STATEFP), "\n", sep = "")
cat("  • CRS: EPSG:5070 (Albers Equal Area Conic - USGS Standard)\n")
cat("  • Base map saved to: figures/01_us_counties_base_map.png\n\n")
cat("  • data_processed/counties_us_shift_5070.rds\n\n")

```


## Step 2: County-Level Road Suffix Summaries

In this step, we summarized road suffix usage for each county using TIGER/Line road shapefiles. Because road data are provided separately for each county, loading all counties at once was not practical, so the data were processed one county at a time. We created a function to download the road file for a county, extract road name information, and compute suffix counts, and then ran this function across three separate scripts, each responsible for a different region of the United States. To reduce runtime, the analysis was limited to a predefined set of official TIGER/Line road suffixes, and suffixes were only matched when they appeared at the end of cleaned road names. The resulting county-level suffix counts, identified by county GEOID, were then combined into a single national dataset in a separate script, where the most frequently used suffix for each county was determined.

```{r eval=FALSE}
# Example of county-level road processing
source("02_process_roads_function.R")

# Run processing for a set of counties (executed in regional scripts)
process_county_roads("55079")

```
## Merging Data and Visualization

In this step, the county-level road suffix summaries were merged with county boundary shape files using the GEOID as a common identifier. This combined dataset allowed us to create a map of the contiguous United States, where each county is colored according to its most common road suffix. The visualization highlights spatial patterns in road naming and demonstrates how attribute data can be integrated with geographic boundaries to produce a clear, interpretable map.

```{r, eval = TRUE}
counties_us_shift_5070 <- readRDS("data_processed/counties_us_shift_5070.rds")
suf <- read.csv("road_suffixes_most_common.csv")
suf$GEOID <- as.numeric(suf$GEOID)
counties_us_shift_5070$GEOID <- as.numeric(counties_us_shift_5070$GEOID)
com <- left_join(counties_us_shift_5070, suf, by = "GEOID")
roadPlot <- ggplot(com) +
  geom_sf(aes(fill = SUFFIX), color = "black", size = 0.1)+
  theme_void()+
  labs(fill = "Most Common Road Suffix",
       title = "Most Common Road Suffix By County")
  
ggsave(
  "roadData.png",
  plot = roadPlot,
  width = 16,
  height = 10,
  dpi = 300,
  units = "in"
)

print(roadPlot)
```

## FEMA Hazard Risk Maps

To demonstrate the flexibility of the spatial framework, we also visualized county-level hazard risk data from FEMA’s National Risk Index. Unlike the road suffix data, this workflow uses a single shapefile containing all counties. We filtered out non-contiguous territories and Alaska/Hawaii, selected relevant hazard columns, replaced placeholder missing values with NA, and reprojected the shapefile for plotting. Separate maps were created for hail and tornado risk by county, using a gradient fill to represent risk values. These maps illustrate that the same geographic framework can be reused for multiple datasets.

```{r}
library(sf)
library(dplyr)
library(tidyverse)
library(leaflet)
library(ggplot2)

# Zip file gotten from "https://hazards.fema.gov/nri/data-resources#shpDownload". Use the "All Counties - County-level detail (Shapefile)" data set

unzip("NRI_Shapefile_Counties.zip", exdir = "temp_shp")
  #unzips the zip file containing the shape files and creates a temporary directory to read from
shp <- st_read("temp_shp/NRI_Shapefile_Counties.shp")
  #read the temp_shp file from the un-zipped zip file
```
```{r}

hailData <- shp %>%
  filter(!STATEFIPS %in% c(78, 72, 69, 66, 60, 15, "02"))%>%
    #filters the data by getting rid of any non US territories and Alaska/hawaii
    #02 is in quotations because it is a character but when 02 was entered it read it as a number so it read it a 2 and would not filter it out
  select(HAIL_RISKS,NRI_ID,COUNTYFIPS,COUNTY,STCOFIPS)%>%
    #selects the hail risks data along with other important data
  mutate(HAIL_RISKS = ifelse(HAIL_RISKS < 0, NA, HAIL_RISKS))
    #the data set sets all NA values to -9999.000000 so this changes those to NA values
hailData <- st_transform(hailData, crs = 4326) 
    #Transforms the shape data to a more graph friendly scale
hData <- ggplot(hailData) +
    #creates the plot
  geom_sf(aes(fill = HAIL_RISKS), color = "black", size = 0.1) +
    #adds the county lines and sets the fill to the hail risk
  scale_fill_gradient(low = "lightblue", high = "darkred", na.value = "grey80") +
    #changes the fill to a gradient
  theme_void() +
  labs(title = "Hail Risk by County",
       fill = "Hail Risk")
    #Adds titles

ggsave(
  "hailData.png",
  plot = hData,
  width = 16,
  height = 10,
  dpi = 300,
  units = "in"
)

tornadoData <- shp %>%
  filter(!STATEFIPS %in% c(78, 72, 69, 66, 60, 15, "02"))%>%
    #filters the data by getting rid of any non US territories and Alaska/hawaii
  select(TRND_RISKS,NRI_ID,COUNTYFIPS,COUNTY,STCOFIPS)%>%
    #selects the tornado risk data along with other important data
  mutate(TRND_RISKS = ifelse(TRND_RISKS < 0, NA, TRND_RISKS))
    #the data set sets all NA values to -9999.000000 so this changes those to NA values
tornadoData <- st_transform(tornadoData, crs = 4326)
    #Transforms the shape data to a more graph friendly scale
tData <- ggplot(tornadoData) +
    #creates the plot
  geom_sf(aes(fill = TRND_RISKS), color = "black", size = 0.1) +
    #adds the county lines and sets the fill to the tornado risk
  scale_fill_gradient(low = "lightblue", high = "darkred", na.value = "grey80") +
    #changes the fill to a gradient
  theme_void() +
  labs(title = "Tornado Risk By County",
       fill = "Tornado Risk")
    #Adds titles to plot

ggsave(
  "tornadoData.png",
  plot = tData,
  width = 16,
  height = 10,
  dpi = 300,
  units = "in"
)

```

## Conclusion

This project shows how publicly available spatial data can be worked with and visualized in R. We processed TIGER/Line road data county by county to figure out the most common road suffixes, and we also mapped FEMA hazard data directly from a single shapefile. Using consistent geographic identifiers and careful data handling made it possible to create clear, reproducible maps that show patterns across the U.S.

